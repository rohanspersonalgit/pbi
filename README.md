# phone-number-parser
## Intro
All questions and responses with the grader can be found [here](https://docs.google.com/document/d/1_hcI9__6hg9Q5p26WI2bImRHECfmWAab1adQ-WP-Y7M/edit?usp=sharing). An HTML file has also been provided in project root as "DoorDashPBIQuestions.html"   

This service exposes a single api("phone-numbers") for use by merchants to provide customer phone numbers. In return the api provides a response containing a count of how many times a unique phone number has been seen. Unique phone numbers are unique combinations of Phone Type and Phone Number.  

The data is provided as a json in the structure below.

```json
INPUT
{"raw_phone_numbers": "(Home)1234567890"}
OUTPUT
{
  "id": "1234567890Home",
  "phone_number": "1234567890",
  "phone_type": "cell",
  "occurences": 1 // int
}

```
input_data is equal to a string and has unclean data. The merchant is not willing to clean up their data and it is
unlikely that the merchant would attempt re-uploading the data.The fact that the merchant is unlikely to reupload guided some assumptions on data parsing and API return values discussed below under "Assumptions". 

## Local deployment 
Run the following commands from project root. THESE COMMANDS ARE MEANT FOR UNIX based, specifically tested on MacOS  
`chmod +xx ./prime.sh must be run once`

Starting Application
```shell
docker-compose down #incase redis instance is still running from past invocation start it again 
docker-compose up # start redis in docker container
./gradlew run # start application 
./prime.sh # This will prime the application to init the controller by sending an empty request. 
```

Unit tests
```shell
./gradlew test
```

Integration tests
```shell
./gradlew integrationTest
```

Jacoco Test Coverage Report
```shell
./gradlew check
```

local manual tests can be ran by requesting localhost:8080/phone-numbers

## Design Choices

### Redis
The reason I chose Redis is due because of the nature of the data being saved. First we can assume that we do not have to worry about other services calling our API or extensibility of the project for now. Secondly the data itself does not really have a relation. Essentially it is just a counter of unique phone numbers. For these two reasons I chose NoSql as it simplifies design. 

In addition to this there are the useful features that redis provides such as in memory caching and persisting database. This provides fast read/writes and also minimizes the amount of code that needs to be written.

Data is currently being stored as a (String,Int) key value. The key is generated by using the phone number + phone type as a unique string. Again as mentioned in assumptions since we are not worried about extending the project currently I found it sufficient to use a phonetype + phone number as the UUID. As these two fields uniquely identify a phone number for our purposes. 


## Assumptions
Below are a list of assumptions made and an explantion of those assumptions influenced the api design
1. Merchant is unlikely to reupload their data.  Because of this assumption the way the algorithm to parse inputs is written is that we are prioritizing saving as many valid inputs. A general structure for the input is here    
```
Valid PhoneType = Exactly one of "(Home)" or "(Cell)
 
Valid Number = Any mix of characters, quotes, spaces, etc. However there must be EXACTLY 10 numbers in the remaining string.
 
End of String: If we encounter a "(" then we have reached the start of a new phone number. Or if there are no 
more characters left in the string then we have reached the end.
For example:
{"raw_phone_numbers":(Home) 6a'55-877-102(Home)123a)sd456ads1234"} =>
{"id": "SomeId", "number": "1234561234", "type": "cell", occurrences: "1"}

Valid PhoneType  + Valid Number can repeat N times. Although we have been told to expect no more then 10 numbers. 

```

2. No need to handle country codes 
3. We can ignore any  whitespace.
4. No need to worry about wrapping area code in brackets
5. If a number is inputted with or without dashes they represent the same number
6. Invalidate any digits longer then 10
7. No more than max 10 phone numbers at once
   1. Based on this I set the limit to the max request size to 10KB. This has space for almost 9000 perfectly formatted entries which is still more then enough room incase the data provided by merchants includes several whitespaces or random charactesr. 
8. The cell phone type must be perfect. Meaning only (Home) or (Cell) are valid values. 
   1. Choice made by me after discussing with Grader. I was told that non-case-sensitive means that we reject the entry. Based on this I chose to reject entries that are not perfect as I see having whitespace or a random qoute in the phone type as an issue as big as being not case sensitive.
9. Max occurrences fits in int size 2,147,647
10. No bad actors trying to fill up our merchants 
11. DO not fail requests taking over 100ms 
12. LOW TPS ~1TPS. Parallel requests are possible. 
    1. Based on the implementation if two requests with the same input come in and they both contain the same unique phone numbers, then one of the requests will output occurrences = n+(numOccurences in input1)  and the other request will output occurences = n+ (numOccurences in input2 + numOccurences in input2).
14. Default JVM memory limits should be sufficient i.e 256 megabytes
15. No need to worry about DB going down, or redundancies.
16. Max up to about 1000 different rows in db. So no need to set resource limits for Docker container
17. No need to worry about idempotency handling
18. No need to worry about extending service to future use cases for now. 



## Example test cases

Explanation: We are counting both numbers as valid as they each have a valid type and contain 10 digits each. Despite the lack of white space
```json
 {"raw_phone_numbers": "(Home)415-415-4154(Cell)123-123-4567" } =>
[{“id”: “someid”, “phone_number”: “4154154155”, "phone_type": "Home"}, “id”: “someid”, “phone_number”: “123-123-4567”, "phone_type": "Cell"}]
```
<br>

Explanation: despite the lack of dashes on input we are counting it as valid.
```json
{"raw_phone_numbers": "(Home)4154154154"} =>
[{“id”: “someid”, “phone_number”: “4154154155”, "phone_type": "Home"}]
```

<br>

Explanation: Assuming I have never seen this number before I return 2 and count both occurrences of it in the input string as valid
```   json
{"raw_phone_numbers": "(Home)415-415-4154(Home)415-415-4154" }
   [{“id”: “someid”, “phone_number”: “4154154155”, "phone_type": "Home", occurrences = 2}]
   ```
<br>

Explanation: We are counting the same number as cell type and a home type in our storage. They are however Unique occurrences and have a unique id each.
```json
   {"raw_phone_numbers": "(Home)415-415-4154(Cell)415-415-4154"}
   [{“id”: “someid”, “phone_number”: “4154154155”, "phone_type": "Home", occurrences = 1}, {“id”: “some_other_id”, “phone_number”: “4154154155”, "phone_type": "Cell", occurrences = 1}]
```



## Future Work  
Currently, the implementation will be slow to start on first request due to how controllers are initialized in micronaut. After the first request the rest of the requests return fairly fast. A temporary solution given is a shell script that can be executed on deployment. Ideally in the past I have dealt with this by including either a additional step in the ci/cd pipeline. Or adding some cron job to regularily prime service. Due to time constraints and nature of the project I chose to leave this.  

Metrics are important to collect here and Micronaut provides some really cool out-of-the-box endpoints and libraries for emitting metrics. However, due to the nature of the project and time constraints I chose to forgo this. 


# Original README.md
## Problem Statement
https://docs.google.com/document/d/1JH8UD2U6is-lJ_ogadIjWASj9ZJw6z0sOIENk_zsomg/edit?usp=sharing
## First-time Setup
1. Clone this repository to some directory on your machine like `~/dev/phone_number_parser`
1. Install IntelliJ IDEA Community (free - available via https://www.jetbrains.com/idea/download/)
1. Install OpenJDK 11 (64-bit). We recommend AdoptOpenJDK, which can be installed like so:
    - OSX:
        - Install `brew` first by visiting https://brew.sh and following the instructions.
        - Run these commands:
          ```
          $ brew tap AdoptOpenJDK/openjdk
          $ brew install --cask adoptopenjdk11
          ```
    - Windows: https://adoptopenjdk.net/installation.html#x64_win-jdk
    - Linux: https://adoptopenjdk.net/installation.html#linux-pkg
1. Install Docker Community Edition: https://docs.docker.com/get-docker/
1. `cd` to the directory you cloned this repository in and bring up the docker container for the DB:
   ```
   $ cd ~/dev/phone_number_parser
   $ docker-compose up
   ```
   If this worked, you'll see a message that looks something like this:
   ```
   db_1  | 2020-12-22 05:57:02.006 UTC [1] LOG:  database system is ready to accept connections
   ```
1. Open IntelliJ, and open the `phone_number_parser` directory.
1. Click Intellij IDEA | Preferences | Build, Execution, Deployment | Compiler | Annotation Processors and ensure Enable annotation processing is checked. Click OK to apply the changes.
1. Click Build -> Rebuild Project and wait for the build to complete successfully
1. Right click on `Application.kt` and click `Run`
1. You should see a log message at the bottom of the console that looks like this:
   ```
   2020-12-21 21:57:08,995 main DEBUG LoggerContext[name=3d4eac69, org.apache.logging.log4j.core.LoggerContext@626abbd0] started OK.
   ```
1. In your browser, navigate to http://localhost:8080/health which should return `{"status": "UP"}`. This means the project is running successfully!

## Common Tasks
- To add a new database migration, just add a new .sql file to resources/db/migration/ with file format `V2__AddSomething.sql`. Migrations get run automatically on application initialization.
- To see which migrations have been applied, visit the following URL after you've started the application: http://localhost:8080/flyway
## Implementation notes
- Micronaut (https://micronaut.io) was chosen as the web framework because that's what we use at DoorDash.
- PostgreSQL, JDBC (connection pooler: hikari), and flyway (database migrations, see docs below) have been set up for you to save you a bit of time. Feel free to swap these components out if you prefer a different database.
- Testcontainers has been set up for you - with testcontainers, the database is automatically cleared after all the tests in the same file complete. Make sure to have your tests in the same file use different data/inputs, otherwise writes could overlap unexpectedly and cause test failures!
## Helpful 3rd Party Library Documentation
### http-client

- [Micronaut HTTP Client documentation](https://docs.micronaut.io/latest/guide/index.html#httpClient)

### sql-jdbi

- [Micronaut Jdbi documentation](https://micronaut-projects.github.io/micronaut-sql/latest/guide/index.html#jdbi)

### testcontainers

- [https://www.testcontainers.org/](https://www.testcontainers.org/)

### flyway

- [Micronaut Flyway Database Migration documentation](https://micronaut-projects.github.io/micronaut-flyway/latest/guide/index.html)

- [https://flywaydb.org/](https://flywaydb.org/)

### jdbc-hikari

- [Micronaut Hikari JDBC Connection Pool documentation](https://micronaut-projects.github.io/micronaut-sql/latest/guide/index.html#jdbc)

